{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f83a52c-a14a-45ac-a5c8-b4543871a473",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8f49b-98f5-44ba-8996-3bffc74e42d4",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68ab3be-a6cf-4716-91d0-cabb1d315e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras, image\n",
    "from keras import layers, models, Input\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Resizing, BatchNormalization, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Normalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "\n",
    "#random seed\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78164e1d-511e-4930-abeb-940812fa64bb",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20ab5b5-6a38-4bb0-93f8-688370e57bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 18:30:12.983227: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 18:30:13.582508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79111 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:07:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "# Creating model architecture\n",
    "\n",
    "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "#making all layers in resnet trainable\n",
    "for layer in base_model.layers[:-50]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = models.Sequential([\n",
    "    Normalization(mean=[0.485, 0.456, 0.406], variance=[0.229, 0.224, 0.225], input_shape=(300, 300, 3)),\n",
    "    Resizing(224, 224),\n",
    "    base_model,\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    BatchNormalization(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d91072-aeb6-4f7b-b56b-889dfbb763cf",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b8d5270-69bc-4d83-b9c7-809b4daf1a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to train the model\n",
    "\n",
    "def train(data, labels, model):\n",
    "\n",
    "    #loading the data\n",
    "    data = np.load(data)\n",
    "    labels = np.load(labels)\n",
    "\n",
    "    #Transposing the data matrix to align dimensions for reshaping\n",
    "    data = data.T\n",
    "\n",
    "    #reshaping the data matrix into images\n",
    "    num_images = data.shape[0]\n",
    "    num_channels = 3\n",
    "\n",
    "    #empty matrix to store reshaped images\n",
    "    images = np.zeros((num_images, 300, 300, num_channels), dtype=np.float32)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image = data[i,:].reshape((300, 300, num_channels))\n",
    "        #standardizing the images by dividing by 255\n",
    "        image = image/255.0\n",
    "        images[i] = image\n",
    "\n",
    "    #done with data array, deleting to free up memory\n",
    "    del data\n",
    "\n",
    "    #validation split\n",
    "\n",
    "    images, val_images, labels, val_labels = train_test_split(images, labels, test_size=0.1, shuffle=True, random_state=0)\n",
    "\n",
    "    #callback checkpoint\n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('model.h5', \n",
    "                                                save_best_only=True)\n",
    "\n",
    "    #fitting the model\n",
    "\n",
    "    history = model.fit(images, labels, epochs=50, batch_size=32, validation_data=(val_images, val_labels), callbacks=[checkpoint_cb])\n",
    "\n",
    "    #returning the history object\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fff56e-eb46-4178-a80c-7f5c34932e22",
   "metadata": {},
   "source": [
    "### Running function. Replace \"data_train.npy\" and \"labels_train.npy\", with the file name for the data and labels that you wish to train with. Include the quotation marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "894da669-b0e1-4839-a569-8edf135ccb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 18:30:24.156301: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8201\n",
      "2023-04-25 18:30:25.285784: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2023-04-25 18:30:25.511380: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-04-25 18:30:26.654995: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - ETA: 0s - loss: 0.8305 - accuracy: 0.7776"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/tensorflow/2.7.0/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 11s 48ms/step - loss: 0.8305 - accuracy: 0.7776 - val_loss: 17.9701 - val_accuracy: 0.3952\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.3963 - accuracy: 0.9019 - val_loss: 0.6570 - val_accuracy: 0.8817\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 4s 35ms/step - loss: 0.3077 - accuracy: 0.9247 - val_loss: 0.6331 - val_accuracy: 0.8898\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.2299 - accuracy: 0.9438 - val_loss: 0.4809 - val_accuracy: 0.9113\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.1827 - accuracy: 0.9567 - val_loss: 0.3608 - val_accuracy: 0.9194\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.1315 - accuracy: 0.9638 - val_loss: 0.3248 - val_accuracy: 0.9382\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.1068 - accuracy: 0.9713 - val_loss: 0.4076 - val_accuracy: 0.9382\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0969 - accuracy: 0.9695 - val_loss: 0.3728 - val_accuracy: 0.9274\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0904 - accuracy: 0.9719 - val_loss: 0.4441 - val_accuracy: 0.9167\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0940 - accuracy: 0.9743 - val_loss: 0.7367 - val_accuracy: 0.8790\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 4s 34ms/step - loss: 0.0650 - accuracy: 0.9818 - val_loss: 0.3219 - val_accuracy: 0.9355\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0589 - accuracy: 0.9845 - val_loss: 0.4330 - val_accuracy: 0.9409\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0531 - accuracy: 0.9848 - val_loss: 0.3567 - val_accuracy: 0.9462\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0601 - accuracy: 0.9812 - val_loss: 0.5047 - val_accuracy: 0.9140\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0590 - accuracy: 0.9839 - val_loss: 0.3704 - val_accuracy: 0.9140\n",
      "Epoch 16/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0641 - accuracy: 0.9827 - val_loss: 0.4641 - val_accuracy: 0.8978\n",
      "Epoch 17/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0360 - accuracy: 0.9886 - val_loss: 0.3267 - val_accuracy: 0.9516\n",
      "Epoch 18/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0187 - accuracy: 0.9952 - val_loss: 0.4261 - val_accuracy: 0.9301\n",
      "Epoch 19/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0333 - accuracy: 0.9904 - val_loss: 0.3552 - val_accuracy: 0.9355\n",
      "Epoch 20/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.4190 - val_accuracy: 0.9194\n",
      "Epoch 21/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0345 - accuracy: 0.9895 - val_loss: 0.4247 - val_accuracy: 0.9274\n",
      "Epoch 22/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0536 - accuracy: 0.9862 - val_loss: 0.4524 - val_accuracy: 0.9167\n",
      "Epoch 23/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0429 - accuracy: 0.9862 - val_loss: 0.3818 - val_accuracy: 0.9409\n",
      "Epoch 24/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.6171 - val_accuracy: 0.8978\n",
      "Epoch 25/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0344 - accuracy: 0.9916 - val_loss: 0.5514 - val_accuracy: 0.8925\n",
      "Epoch 26/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0437 - accuracy: 0.9868 - val_loss: 0.3865 - val_accuracy: 0.9247\n",
      "Epoch 27/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0388 - accuracy: 0.9886 - val_loss: 0.3896 - val_accuracy: 0.9355\n",
      "Epoch 28/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0580 - accuracy: 0.9812 - val_loss: 0.4677 - val_accuracy: 0.9194\n",
      "Epoch 29/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0450 - accuracy: 0.9865 - val_loss: 0.3865 - val_accuracy: 0.9328\n",
      "Epoch 30/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0356 - accuracy: 0.9901 - val_loss: 0.3954 - val_accuracy: 0.9382\n",
      "Epoch 31/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 0.3457 - val_accuracy: 0.9462\n",
      "Epoch 32/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0291 - accuracy: 0.9910 - val_loss: 0.4279 - val_accuracy: 0.9247\n",
      "Epoch 33/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0370 - accuracy: 0.9880 - val_loss: 0.4763 - val_accuracy: 0.9220\n",
      "Epoch 34/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 0.4300 - val_accuracy: 0.9409\n",
      "Epoch 35/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.5004 - val_accuracy: 0.9435\n",
      "Epoch 36/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0117 - accuracy: 0.9955 - val_loss: 0.4627 - val_accuracy: 0.9462\n",
      "Epoch 37/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 0.4614 - val_accuracy: 0.9382\n",
      "Epoch 38/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0277 - accuracy: 0.9940 - val_loss: 0.4882 - val_accuracy: 0.9274\n",
      "Epoch 39/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0298 - accuracy: 0.9919 - val_loss: 0.4584 - val_accuracy: 0.9409\n",
      "Epoch 40/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0351 - accuracy: 0.9895 - val_loss: 0.3494 - val_accuracy: 0.9409\n",
      "Epoch 41/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0476 - accuracy: 0.9871 - val_loss: 0.4145 - val_accuracy: 0.9409\n",
      "Epoch 42/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.4449 - val_accuracy: 0.9301\n",
      "Epoch 43/50\n",
      "105/105 [==============================] - 3s 29ms/step - loss: 0.0314 - accuracy: 0.9910 - val_loss: 0.4212 - val_accuracy: 0.9409\n",
      "Epoch 44/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.4642 - val_accuracy: 0.9355\n",
      "Epoch 45/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0412 - accuracy: 0.9895 - val_loss: 0.5444 - val_accuracy: 0.9274\n",
      "Epoch 46/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0386 - accuracy: 0.9886 - val_loss: 0.5096 - val_accuracy: 0.9140\n",
      "Epoch 47/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0311 - accuracy: 0.9925 - val_loss: 0.4950 - val_accuracy: 0.9194\n",
      "Epoch 48/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.4056 - val_accuracy: 0.9355\n",
      "Epoch 49/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0296 - accuracy: 0.9919 - val_loss: 0.4270 - val_accuracy: 0.9220\n",
      "Epoch 50/50\n",
      "105/105 [==============================] - 3s 30ms/step - loss: 0.0166 - accuracy: 0.9940 - val_loss: 0.4406 - val_accuracy: 0.9355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b0885c65550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\"data_train.npy\", \"labels_train.npy\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.7.0",
   "language": "python",
   "name": "tensorflow-2.7.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
